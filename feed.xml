<?xml version='1.0' encoding='utf-8'?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Google Developers Search Blog</title>
    <link>https://developers.googleblog.com/en/search/</link>
    <description>Latest updates from Google Developers Search team</description>
    <language>en-us</language>
    <lastBuildDate>Wed, 10 Sep 2025 01:24:53 +0000</lastBuildDate>
    <atom:link href="https://lawvia.github.io/google-dev-rss/feed.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Beyond backpropagation: JAX's symbolic power unlocks new frontiers in scientific computing</title>
      <link>https://developers.googleblog.com/en/jax-symbolic-power-unlocks-new-frontiers-in-scientific-computing/</link>
      <description>&lt;![CDATA[&lt;img src="https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/JAXs-Symbolic-Power-Blog-Meta.2e16d0ba.fill-800x400.jpg" alt="JAX's-Symbolic-Power-Blog-Meta" style="max-width: 100%; height: auto;"&gt;&lt;br&gt;&lt;br&gt;JAX, a framework known for large-scale AI model development, is proving to be a powerful tool in scientific computing, particularly for solving complex Partial Differential Equations (PDEs), now being leveraged by researchers to achieve significant speed-ups and memory reductions in solving high-order PDEs and demonstrating its potential to unlock new frontiers in scientific discovery.]]&gt;</description>
      <pubDate>Wed, 10 Sep 2025 01:24:53 +0000</pubDate>
      <guid>https://developers.googleblog.com/en/jax-symbolic-power-unlocks-new-frontiers-in-scientific-computing/</guid>
      <enclosure url="https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/JAXs-Symbolic-Power-Blog-Meta.2e16d0ba.fill-800x400.jpg" type="image/png" />
    </item>
    <item>
      <title>A2A Extensions: Empowering Custom Agent Functionality</title>
      <link>https://developers.googleblog.com/en/a2a-extensions-empowering-custom-agent-functionality/</link>
      <description>&lt;![CDATA[&lt;img src="https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/GfD_evergreen_meta.2e16d0ba.fill-800x400.png" alt="GfD_evergreen_meta" style="max-width: 100%; height: auto;"&gt;&lt;br&gt;&lt;br&gt;A2A Extensions provide a flexible way to add custom functionalities to agent-to-agent communication, going beyond the core A2A protocol. They enable specialized features and are openly defined and implemented.]]&gt;</description>
      <pubDate>Wed, 10 Sep 2025 01:24:53 +0000</pubDate>
      <guid>https://developers.googleblog.com/en/a2a-extensions-empowering-custom-agent-functionality/</guid>
      <enclosure url="https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/GfD_evergreen_meta.2e16d0ba.fill-800x400.png" type="image/png" />
    </item>
    <item>
      <title>Veo 3 and Veo 3 Fast – new pricing, new configurations and better resolution</title>
      <link>https://developers.googleblog.com/en/veo-3-and-veo-3-fast-new-pricing-new-configurations-and-better-resolution/</link>
      <description>&lt;![CDATA[&lt;img src="https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/image1_UYdtEmV.2e16d0ba.fill-800x400.png" alt="veo3-generally-available-social" style="max-width: 100%; height: auto;"&gt;&lt;br&gt;&lt;br&gt;Today, we’re launching three big Veo updates: support for vertical format outputs (9:16 aspect ratio...]]&gt;</description>
      <pubDate>Wed, 10 Sep 2025 01:24:53 +0000</pubDate>
      <guid>https://developers.googleblog.com/en/veo-3-and-veo-3-fast-new-pricing-new-configurations-and-better-resolution/</guid>
      <enclosure url="https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/image1_UYdtEmV.2e16d0ba.fill-800x400.png" type="image/png" />
    </item>
    <item>
      <title>Google AI Edge Gallery: Now with audio and on Google Play</title>
      <link>https://developers.googleblog.com/en/google-ai-edge-gallery-now-with-audio-and-on-google-play/</link>
      <description>&lt;![CDATA[&lt;img src="https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/google-ai-edge-gallery_1.2e16d0ba.fill-800x400.png" alt="google-ai-edge-gallery" style="max-width: 100%; height: auto;"&gt;&lt;br&gt;&lt;br&gt;Google AI Edge has expanded the Gemma 3n preview to include audio support. Users can play with it on their own mobile phone using the Google AI Edge Gallery, which is now available in Open Beta on Play Store.]]&gt;</description>
      <pubDate>Wed, 10 Sep 2025 01:24:53 +0000</pubDate>
      <guid>https://developers.googleblog.com/en/google-ai-edge-gallery-now-with-audio-and-on-google-play/</guid>
      <enclosure url="https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/google-ai-edge-gallery_1.2e16d0ba.fill-800x400.png" type="image/png" />
    </item>
    <item>
      <title>From Fine-Tuning to Production: A Scalable Embedding Pipeline with Dataflow</title>
      <link>https://developers.googleblog.com/en/deploying-embeddinggemma-at-scale-with-dataflow/</link>
      <description>&lt;![CDATA[&lt;img src="https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/EGDataflow_Metadatal_RD1-V01_qBoeg.2e16d0ba.fill-800x400.jpg" alt="EG+Dataflow_Metadatal" style="max-width: 100%; height: auto;"&gt;&lt;br&gt;&lt;br&gt;Learn how to use Google's EmbeddingGemma, an efficient open model, with Google Cloud's Dataflow and vector databases like AlloyDB to build scalable, real-time knowledge ingestion pipelines.]]&gt;</description>
      <pubDate>Wed, 10 Sep 2025 01:24:53 +0000</pubDate>
      <guid>https://developers.googleblog.com/en/deploying-embeddinggemma-at-scale-with-dataflow/</guid>
      <enclosure url="https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/EGDataflow_Metadatal_RD1-V01_qBoeg.2e16d0ba.fill-800x400.jpg" type="image/png" />
    </item>
    <item>
      <title>Introducing EmbeddingGemma: The Best-in-Class Open Model for On-Device Embeddings</title>
      <link>https://developers.googleblog.com/en/introducing-embeddinggemma/</link>
      <description>&lt;![CDATA[&lt;img src="https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/EmbeddingGemma_Metadatal_RD2-V01.2e16d0ba.fill-800x400.jpg" alt="EmbeddingGemma_Metadata" style="max-width: 100%; height: auto;"&gt;&lt;br&gt;&lt;br&gt;Introducing EmbeddingGemma: a new embedding model designed for efficient on-device AI applications from Google. This open model is the highest-ranking text-only multilingual embedding model under 500M parameters on the MTEB benchmark, enabling powerful features like RAG and semantic search directly on mobile devices without an internet connection.]]&gt;</description>
      <pubDate>Wed, 10 Sep 2025 01:24:53 +0000</pubDate>
      <guid>https://developers.googleblog.com/en/introducing-embeddinggemma/</guid>
      <enclosure url="https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/EmbeddingGemma_Metadatal_RD2-V01.2e16d0ba.fill-800x400.jpg" type="image/png" />
    </item>
    <item>
      <title>How to prompt Gemini 2.5 Flash Image Generation for the best results</title>
      <link>https://developers.googleblog.com/en/how-to-prompt-gemini-2-5-flash-image-generation-for-the-best-results/</link>
      <description>&lt;![CDATA[&lt;img src="https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Gemini2.5FlashImage_Metadatal_RD1-.2e16d0ba.fill-800x400.jpg" alt="Gemini 2.5 Flash Image" style="max-width: 100%; height: auto;"&gt;&lt;br&gt;&lt;br&gt;Detailed prompting techniques and best practices for various applications, including photorealistic scenes, stylized illustrations, product mockups, and more using Google's newly released Gemini 2.5 Flash Image; a natively multimodal model capable of generating, editing, and composing images using text, supporting capabilities like text-to-image, image editing, style transfer, and multi-image composition.]]&gt;</description>
      <pubDate>Thu, 28 Aug 2025 00:00:00 +0000</pubDate>
      <guid>https://developers.googleblog.com/en/how-to-prompt-gemini-2-5-flash-image-generation-for-the-best-results/</guid>
      <enclosure url="https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Gemini2.5FlashImage_Metadatal_RD1-.2e16d0ba.fill-800x400.jpg" type="image/png" />
    </item>
    <item>
      <title>Beyond the terminal: Gemini CLI comes to Zed</title>
      <link>https://developers.googleblog.com/en/gemini-cli-is-now-integrated-into-zed/</link>
      <description>&lt;![CDATA[&lt;img src="https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/CLI-Metadatal_RD2-V01.2e16d0ba.fill-800x400.jpg" alt="Gemini CLI is now integrated into Zed, bringing AI directly to your code editor" style="max-width: 100%; height: auto;"&gt;&lt;br&gt;&lt;br&gt;Google and Zed have partnered to integrate Gemini CLI directly into the Zed code editor, bringing AI capabilities directly into the editor for developers and allowing for faster and more focused coding, enabling tasks like in-place code generation, instant answers, and natural chat within the terminal with a seamless review workflow for AI-generated changes.]]&gt;</description>
      <pubDate>Wed, 27 Aug 2025 00:00:00 +0000</pubDate>
      <guid>https://developers.googleblog.com/en/gemini-cli-is-now-integrated-into-zed/</guid>
      <enclosure url="https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/CLI-Metadatal_RD2-V01.2e16d0ba.fill-800x400.jpg" type="image/png" />
    </item>
    <item>
      <title>Stop “vibe testing” your LLMs. It's time for real evals.</title>
      <link>https://developers.googleblog.com/en/streamline-llm-evaluation-with-stax/</link>
      <description>&lt;![CDATA[&lt;img src="https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/stax-launch.2e16d0ba.fill-800x400.png" alt="Stax" style="max-width: 100%; height: auto;"&gt;&lt;br&gt;&lt;br&gt;Stax, an experimental developer tool, addresses the insufficient nature of "vibe testing" LLMs by streamlining the LLM evaluation lifecycle, allowing users to rigorously test their AI stack and make data-driven decisions through human labeling and scalable LLM-as-a-judge auto-raters.]]&gt;</description>
      <pubDate>Wed, 27 Aug 2025 00:00:00 +0000</pubDate>
      <guid>https://developers.googleblog.com/en/streamline-llm-evaluation-with-stax/</guid>
      <enclosure url="https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/stax-launch.2e16d0ba.fill-800x400.png" type="image/png" />
    </item>
    <item>
      <title>Introducing Gemini 2.5 Flash Image, our state-of-the-art image model</title>
      <link>https://developers.googleblog.com/en/introducing-gemini-2-5-flash-image/</link>
      <description>&lt;![CDATA[&lt;img src="https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Gemini2.5Flash-Metadata-Altl_RD4-V.2e16d0ba.fill-800x400.jpg" alt="Introducing Gemini 2.5 Flash Image" style="max-width: 100%; height: auto;"&gt;&lt;br&gt;&lt;br&gt;Gemini 2.5 Flash Image is a new state-of-the-art image generation and editing model that allows for blending multiple images, maintaining character consistency, and targeted transformations using natural language, leveraging Gemini's world knowledge, now available through the Gemini API, Google AI Studio, and Vertex AI.]]&gt;</description>
      <pubDate>Tue, 26 Aug 2025 00:00:00 +0000</pubDate>
      <guid>https://developers.googleblog.com/en/introducing-gemini-2-5-flash-image/</guid>
      <enclosure url="https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Gemini2.5Flash-Metadata-Altl_RD4-V.2e16d0ba.fill-800x400.jpg" type="image/png" />
    </item>
  </channel>
</rss>